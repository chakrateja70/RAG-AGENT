{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPfve5OxqouUbn4Hee60QFq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chakrateja70/RAG-AGENT/blob/main/Agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_openai langchain langchain_chroma docx2txt langchain_community langchain_text_splitters pypdf weaviate-client"
      ],
      "metadata": {
        "collapsed": true,
        "id": "4ietG2X05eeR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "TYzr-bguOonD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import langchain\n",
        "print(langchain.__version__)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "WFl4zM7npqwh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Required API Keys**\n"
      ],
      "metadata": {
        "id": "a1t68an8NFtY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "NU12IkDCf-UM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
        "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
        "os.environ['LANGCHAIN_API_KEY'] = \"api_key\"\n",
        "os.environ['OPENAI_API_KEY'] = \"api_key\"\n"
      ],
      "metadata": {
        "id": "ObAQ9S62u7yd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *Loading PDF*"
      ],
      "metadata": {
        "id": "L4RjivlVMyln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader, Docx2txtLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from typing import List\n",
        "from langchain_core.documents import Document\n",
        "import os\n",
        "\n",
        "def load_documents(folder_path: str) -> List[Document]:\n",
        "    pages = []\n",
        "    for filename in os.listdir(folder_path):\n",
        "        file_path = os.path.join(folder_path, filename)\n",
        "        if filename.endswith('.pdf'):\n",
        "            loader = PyPDFLoader(file_path)\n",
        "        elif filename.endswith('.docx'):\n",
        "            loader = Docx2txtLoader(file_path)\n",
        "        else:\n",
        "            print(f\"Unsupported file type: {filename}\")\n",
        "            continue\n",
        "        pages.extend(loader.load())\n",
        "    return pages\n",
        "\n",
        "folder_path = \"/content/\"\n",
        "pages = load_documents(folder_path)\n",
        "print(f\"Loaded {len(pages)} documents from the folder.\")\n"
      ],
      "metadata": {
        "id": "K1Q3XE9bk3cS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3Q4pp6dYXjvn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "# loader = PyPDFLoader(\"/content/docs/NLP.pdf\")\n",
        "# pages = []\n",
        "# async for page in loader.alazy_load():\n",
        "#     pages.append(page)"
      ],
      "metadata": {
        "id": "SV0E_FP0JIaz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d16e064-6cda-4ec1-c05c-7dd769042ec0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pypdf._reader:Ignoring wrong pointing object 31 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 32 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 89 0 (offset 0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pages"
      ],
      "metadata": {
        "collapsed": true,
        "id": "GcRZ7jBLLsv1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *splitting text from above loaded PDF*"
      ],
      "metadata": {
        "id": "_mfpzb-YPhmd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    # Set a really small chunk size, just to show.\n",
        "    chunk_size=3500,\n",
        "    chunk_overlap=100,\n",
        "    length_function=len,\n",
        "    is_separator_regex=False,\n",
        ")\n",
        "splits = text_splitter.split_documents(pages)\n",
        "print(f\"split the document into  {len(splits)} chunks.\")"
      ],
      "metadata": {
        "id": "SdpbrNPIOvUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(1, splits[2].page_content)"
      ],
      "metadata": {
        "id": "QIjR763vQGHa",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3HHuc-zCkBYz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *Embedding the Chunk of documents*"
      ],
      "metadata": {
        "id": "VT4dyJgcXUhy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
        "\n",
        "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "document_embeddings = embedding_function.embed_documents([split.page_content for split in splits])\n"
      ],
      "metadata": {
        "id": "Vr5cNTTaX4mu",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document_embeddings"
      ],
      "metadata": {
        "collapsed": true,
        "id": "zycnKoFhVCJJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "SOMdBAZio-U4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *Storing data in chroma*"
      ],
      "metadata": {
        "id": "PWkF1GLvYaM_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_chroma import Chroma\n",
        "from langchain_community.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
        "\n",
        "# Define embedding model\n",
        "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# Define Chroma vector database\n",
        "vectordb = Chroma.from_documents(\n",
        "    documents=splits,  # Ensure `splits` contains the list of document chunks\n",
        "    embedding=embedding_function,\n",
        "    persist_directory=\"./chroma.db\"  # Specify directory to persist the database\n",
        ")\n",
        "\n",
        "print(\"Vector store created and persisted to './chroma.db'\")\n"
      ],
      "metadata": {
        "id": "ADFRFwvCZEMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *Performing Similarity Search*"
      ],
      "metadata": {
        "id": "P5c1vmQiCUIJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "query = \"what is oops?\"\n",
        "search_results = vectordb.similarity_search(query, k=5)\n",
        "print(f\"\\nTop 2 most relevant chunks for the query: '{query}'\\n\")\n",
        "for i, result in enumerate(search_results, 1):\n",
        "    print(f\"Result {i}:\")\n",
        "    print(f\"Source: {result.metadata.get('source', 'Unknown')}\")\n",
        "    print(f\"Content: {result.page_content}\")\n",
        "    print()\n"
      ],
      "metadata": {
        "id": "aRdgpvpnA4rC",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Retrival of relavant data*"
      ],
      "metadata": {
        "id": "kTzOHI_xD_Vz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectordb.as_retriever(search_kwargs={\"k\": 2})\n",
        "retriever_results = retriever.invoke(\"what is nxtwave?\")\n",
        "print(retriever_results)\n"
      ],
      "metadata": {
        "id": "92MfCjvDCWYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VALCPWioYFKd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}